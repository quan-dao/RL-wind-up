{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "from math import sqrt\n",
    "\n",
    "from itertools import count\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Buffer of Transition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', \n",
    "                       ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "    \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) == self.capacity:\n",
    "            self.memory.pop()\n",
    "        \n",
    "        self.memory.insert(0, Transition(*args))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size) # a list of element from self.memory\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critic - Q Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level information - Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        '''\n",
    "        2 Hidden layers\n",
    "        400 & 300 units each\n",
    "        action is only introduced in 2nd hidden layer\n",
    "        '''\n",
    "        super(Critic, self).__init__()\n",
    "        self.l1 = nn.Linear(state_dim, 400)\n",
    "        self.l2 = nn.Linear(400 + action_dim, 300)\n",
    "        self.l3 = nn.Linear(300, 1)\n",
    "        \n",
    "        # weight init\n",
    "        nn.init.uniform_(self.l1.weight, a=-1./sqrt(state_dim), b=1./sqrt(state_dim))\n",
    "        nn.init.uniform_(self.l2.weight, a=-1./sqrt(400 + action_dim), b=1./sqrt(400 + action_dim))\n",
    "        nn.init.uniform_(self.l3.weight, a=-3*1e-3, b=3*1e-3)\n",
    "        # bias init\n",
    "        nn.init.uniform_(self.l1.bias, a=-1./sqrt(state_dim), b=1./sqrt(state_dim))\n",
    "        nn.init.uniform_(self.l2.bias, a=-1./sqrt(400 + action_dim), b=1./sqrt(400 + action_dim))\n",
    "        nn.init.uniform_(self.l3.bias, a=-3*1e-3, b=3*1e-3)\n",
    "\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = F.relu(self.l1(state))\n",
    "        x = F.relu(self.l2(torch.cat([x, action], dim=1)))\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixels - Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, H_in, W_in):\n",
    "        super(PixelCritic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        def conv_size_out(size_in, stride=2, kernel_size=5, padding=0):\n",
    "            return (size_in + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
    "        \n",
    "        conv_H_out = conv_size_out(conv_size_out(conv_size_out(H_in, stride=1)))\n",
    "        conv_W_out = conv_size_out(conv_size_out(conv_size_out(W_in, stride=1)))\n",
    "         \n",
    "        linear_input_size = conv_H_out * conv_W_out * 32 + action_dim\n",
    "        self.fcn1 = nn.Linear(linear_input_size, 200)  # action is included here\n",
    "        self.fcn2 = nn.Linear(200, 1)\n",
    "        \n",
    "        # weight init\n",
    "        fan_in = 32 * 5 * 5  # num_filters * filter_h * filer_w\n",
    "        nn.init.uniform_(self.conv1.weight, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv2.weight, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv3.weight, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.fcn1.weight, a=-1./sqrt(linear_input_size), b=1./sqrt(linear_input_size))\n",
    "        nn.init.uniform_(self.fcn2.weight, a=-3*1e-4, b=3*1e-4)\n",
    "        #bias init\n",
    "        nn.init.uniform_(self.conv1.bias, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv2.bias, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv3.bias, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.fcn1.bias, a=-1./sqrt(linear_input_size), b=1./sqrt(linear_input_size))\n",
    "        nn.init.uniform_(self.fcn2.bias, a=-3*1e-4, b=3*1e-4)\n",
    "    \n",
    "    def forward(self, screen, action):\n",
    "        x = F.relu(self.bn1(self.conv1(screen)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        fcn_x = F.relu(self.fcn1(torch.cat([x.reshape((x.size(0), -1)), action], dim=1)))\n",
    "        out = self.fcn2(fcn_x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor - Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-level Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, sup_action):\n",
    "        super(Actor, self).__init__()\n",
    "        self.l1 = nn.Linear(state_dim, 400)\n",
    "        self.l2 = nn.Linear(400, 300)\n",
    "        self.l3 = nn.Linear(300, action_dim)\n",
    "        self.sup_action = sup_action  # suppermum of action space\n",
    "        \n",
    "        # weight init\n",
    "        nn.init.uniform_(self.l1.weight, a=-1./sqrt(state_dim), b=1./sqrt(state_dim))\n",
    "        nn.init.uniform_(self.l2.weight, a=-1./sqrt(400), b=1./sqrt(400))\n",
    "        nn.init.uniform_(self.l3.weight, a=-3*1e-3, b=3*1e-3)\n",
    "        # bias init\n",
    "        nn.init.uniform_(self.l1.bias, a=-1./sqrt(state_dim), b=1./sqrt(state_dim))\n",
    "        nn.init.uniform_(self.l2.bias, a=-1./sqrt(400), b=1./sqrt(400))\n",
    "        nn.init.uniform_(self.l3.bias, a=-3*1e-3, b=3*1e-3)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.l1(state))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.sup_action * torch.tanh(self.l3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixels Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelActor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, sup_action, H_in, W_in):\n",
    "        super(PixelActor, self).__init__()\n",
    "        self.sup_action = sup_action\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        def conv_size_out(size_in, stride=2, kernel_size=5, padding=0):\n",
    "            return (size_in + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
    "        \n",
    "        conv_H_out = conv_size_out(conv_size_out(conv_size_out(H_in, stride=1)))\n",
    "        conv_W_out = conv_size_out(conv_size_out(conv_size_out(W_in, stride=1)))\n",
    "         \n",
    "        linear_input_size = conv_H_out * conv_W_out * 32\n",
    "        self.fcn1 = nn.Linear(linear_input_size, 200)  \n",
    "        self.fcn2 = nn.Linear(200, 1)\n",
    "        \n",
    "        # weight init\n",
    "        fan_in = 32 * 5 * 5  # num_filters * filter_h * filer_w\n",
    "        nn.init.uniform_(self.conv1.weight, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv2.weight, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv3.weight, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.fcn1.weight, a=-1./sqrt(linear_input_size), b=1./sqrt(linear_input_size))\n",
    "        nn.init.uniform_(self.fcn2.weight, a=-3*1e-4, b=3*1e-4)\n",
    "        #bias init\n",
    "        nn.init.uniform_(self.conv1.bias, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv2.bias, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.conv3.bias, a=-1./sqrt(fan_in), b = 1./sqrt(fan_in))\n",
    "        nn.init.uniform_(self.fcn1.bias, a=-1./sqrt(linear_input_size), b=1./sqrt(linear_input_size))\n",
    "        nn.init.uniform_(self.fcn2.bias, a=-3*1e-4, b=3*1e-4)\n",
    "    \n",
    "    def forward(self, screen):\n",
    "        x = F.relu(self.bn1(self.conv1(screen)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        fcn_x = F.relu(self.fcn1(x.reshape((x.size(0), -1))))\n",
    "        out = torch.tanh(self.fcn2(fcn_x)) * self.sup_action\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG (mainly everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG(object):\n",
    "    def __init__(self, state_dim, action_dim, sup_action, memory_capacity, batch_size, \n",
    "                 gamma=0.99, critic_lr=1e-3, actor_lr=1e-4, polyak=0.999):\n",
    "        # critic\n",
    "        self.critic = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=critic_lr, weight_decay=1e-2)\n",
    "        \n",
    "        self.critic_target = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "\n",
    "        # actor\n",
    "        self.actor = Actor(state_dim, action_dim, sup_action).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "        \n",
    "        self.actor_target = Actor(state_dim, action_dim, sup_action).to(device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        \n",
    "        # replay buffer\n",
    "        self.replay_buffer = ReplayBuffer(memory_capacity)\n",
    "        # hyper parameters\n",
    "        self.BATCH_SIZE = batch_size\n",
    "        self.GAMMA = gamma\n",
    "        self.polyak = polyak\n",
    "    \n",
    "    def train(self, iteration):\n",
    "        avg_critic_loss = 0\n",
    "        avg_actor_loss = 0\n",
    "        for i in range(iteration):\n",
    "            # sample exp from replay buffer\n",
    "            transitions = self.replay_buffer.sample(self.BATCH_SIZE)\n",
    "            batch = Transition(*zip(*transitions))\n",
    "            # pull out index (i.e. mask) in the batch & next_state of transitions having next_state is not None\n",
    "            mask_nonFinal_next_states = torch.tensor(tuple(map(lambda s: s is not None, \n",
    "                                                              batch.next_state)), device=device, dtype=torch.uint8)\n",
    "            nonFinal_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                 if s is not None])\n",
    "            # construct tensor of state, action, reward\n",
    "            states_batch = torch.cat(batch.state)\n",
    "            actions_batch = torch.cat(batch.action)\n",
    "            reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "            # compute TD target\n",
    "            next_state_act_val = torch.zeros([self.BATCH_SIZE, 1], device=device)\n",
    "    #         print(self.actor_target(nonFinal_next_states))\n",
    "    #         print(\"nonFinal_next_states:\\n\", nonFinal_next_states)\n",
    "    #         print(\"critic output:\\n\",self.critic_target(nonFinal_next_states, \n",
    "    #                                                                         self.actor_target(nonFinal_next_states)))\n",
    "    #         print(\"mask_nonFinal_next_states:\\n\", mask_nonFinal_next_states)\n",
    "            next_state_act_val[mask_nonFinal_next_states] = self.critic_target(nonFinal_next_states, \n",
    "                                                                            self.actor_target(nonFinal_next_states))\n",
    "            td_target = reward_batch + self.GAMMA * next_state_act_val.detach()\n",
    "\n",
    "            critic_loss = F.mse_loss(self.critic(states_batch, actions_batch), td_target)  # MS of td_error\n",
    "            avg_critic_loss += critic_loss.item()\n",
    "            \n",
    "            # call optimizer of critic to minimize loss\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward(retain_graph=True)\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "            # Update actor\n",
    "            actor_loss = -self.critic(states_batch, self.actor(states_batch)).mean() \n",
    "            avg_actor_loss += actor_loss.item()\n",
    "            \n",
    "            self.actor_optimizer.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizer.step()\n",
    "\n",
    "            # Update target actor & target critic\n",
    "            with torch.no_grad():\n",
    "                for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "                    target_param.data.copy_((1 - self.polyak) * param.data + self.polyak * target_param.data)\n",
    "\n",
    "                for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "                    target_param.data.copy_((1 - self.polyak) * param.data + self.polyak * target_param.data)\n",
    "            \n",
    "            return avg_critic_loss/iteration, avg_actor_loss/iteration\n",
    "    \n",
    "    def select_action(self, state):\n",
    "#         state = torch.FloatTensor(state.reshape(1, -1)).to(device)\n",
    "#         return self.actor(state).cpu().data.numpy().flatten()\n",
    "        return self.actor(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(np_array):\n",
    "    '''\n",
    "    convert 1d np array to tensor (written as a row vector)\n",
    "    '''\n",
    "    return torch.FloatTensor(np_array.reshape(1, -1)).to(device)\n",
    "\n",
    "def checkout_actor(render=False):\n",
    "    state = env.reset()\n",
    "    state = to_tensor(state)\n",
    "    accu_reward = 0\n",
    "    for step in count():\n",
    "        action = agent.actor(state).detach()\n",
    "        \n",
    "        _act = action.cpu()\n",
    "        next_state, reward, done, _ = env.step(_act.data.numpy().flatten())\n",
    "        accu_reward += reward\n",
    "        next_state = to_tensor(next_state)\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            print(\"Episode %d [ACTOR] Finish after %d step\\tAccumulated reward:%.3f\" % (i_episode, step+1, accu_reward))\n",
    "            print(\"-------------------------------------\")\n",
    "            break\n",
    "        # Move on \n",
    "        state.data.copy_(next_state.data)\n",
    "    return accu_reward\n",
    "\n",
    "# checkout_actor()\n",
    "# time.sleep(1)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "sup_action = torch.Tensor(env.action_space.high).to(device)\n",
    "\n",
    "memory_capacity = int(1e6)\n",
    "batch_size = 64\n",
    "\n",
    "agent = DDPG(state_dim, action_dim, sup_action, memory_capacity, batch_size)\n",
    "\n",
    "actor_accumulated_reward = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish collecting experience after 20 episode\n",
      "Episode 50 [ACTOR] Finish after 67 step\tAccumulated reward:-543.406\n",
      "-------------------------------------\n",
      "Episode 100 [ACTOR] Finish after 74 step\tAccumulated reward:-579.475\n",
      "-------------------------------------\n",
      "Episode 150 [ACTOR] Finish after 55 step\tAccumulated reward:-455.201\n",
      "-------------------------------------\n",
      "Episode 200 [ACTOR] Finish after 75 step\tAccumulated reward:-802.874\n",
      "-------------------------------------\n",
      "Episode 250 [ACTOR] Finish after 159 step\tAccumulated reward:-348.324\n",
      "-------------------------------------\n",
      "Episode 300 [ACTOR] Finish after 122 step\tAccumulated reward:-250.182\n",
      "-------------------------------------\n",
      "Episode 350 [ACTOR] Finish after 110 step\tAccumulated reward:-312.520\n",
      "-------------------------------------\n",
      "Episode 400 [ACTOR] Finish after 87 step\tAccumulated reward:-348.852\n",
      "-------------------------------------\n",
      "Episode 450 [ACTOR] Finish after 84 step\tAccumulated reward:-424.743\n",
      "-------------------------------------\n",
      "Episode 500 [ACTOR] Finish after 274 step\tAccumulated reward:-616.005\n",
      "-------------------------------------\n",
      "Episode 550 [ACTOR] Finish after 211 step\tAccumulated reward:-717.829\n",
      "-------------------------------------\n",
      "Episode 600 [ACTOR] Finish after 166 step\tAccumulated reward:-577.645\n",
      "-------------------------------------\n",
      "Episode 650 [ACTOR] Finish after 109 step\tAccumulated reward:-484.586\n",
      "-------------------------------------\n",
      "Episode 700 [ACTOR] Finish after 179 step\tAccumulated reward:-544.058\n",
      "-------------------------------------\n",
      "Episode 750 [ACTOR] Finish after 91 step\tAccumulated reward:-417.367\n",
      "-------------------------------------\n",
      "Episode 800 [ACTOR] Finish after 114 step\tAccumulated reward:-281.742\n",
      "-------------------------------------\n",
      "Episode 850 [ACTOR] Finish after 115 step\tAccumulated reward:-268.481\n",
      "-------------------------------------\n",
      "Episode 900 [ACTOR] Finish after 108 step\tAccumulated reward:-336.214\n",
      "-------------------------------------\n",
      "Episode 950 [ACTOR] Finish after 95 step\tAccumulated reward:-243.140\n",
      "-------------------------------------\n",
      "Episode 1000 [ACTOR] Finish after 80 step\tAccumulated reward:-38.051\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "max_episode = 1001\n",
    "max_random_action_steps = 3000\n",
    "random_action_steps = 0\n",
    "\n",
    "flag_collecting_exp = True\n",
    "\n",
    "act_noise = 0.075\n",
    "\n",
    "for i_episode in range(max_episode):\n",
    "    state = env.reset()\n",
    "    state = to_tensor(state)\n",
    "    for step in count():\n",
    "        # Choose action\n",
    "        if random_action_steps < max_random_action_steps:\n",
    "            action = to_tensor(env.action_space.sample())\n",
    "            random_action_steps += 1\n",
    "        else:\n",
    "            action = agent.select_action(state)    \n",
    "        \n",
    "        # take action & observe next state & reward\n",
    "        _act = action.cpu().data.numpy().flatten()\n",
    "        _act = np.random.normal(_act, act_noise).clip(env.action_space.low, env.action_space.high)\n",
    "                                                                                             \n",
    "        next_state, reward, done, _ = env.step(_act)\n",
    "        next_state = to_tensor(next_state)\n",
    "        reward = to_tensor(np.array([reward]))\n",
    "        \n",
    "        # update replay buffer\n",
    "        action = to_tensor(_act)\n",
    "        agent.replay_buffer.push(state, action, next_state, reward)\n",
    "        \n",
    "        # check if replay_buffer is enough for update\n",
    "        if not flag_collecting_exp:\n",
    "            avg_critic_loss, avg_actor_loss = agent.train(iteration=15)\n",
    "        else:\n",
    "            if agent.replay_buffer.__len__() > max_random_action_steps:\n",
    "                flag_collecting_exp = False  # stop collecting experinences\n",
    "                print(\"Finish collecting experience after %d episode\" % i_episode)\n",
    "        \n",
    "        if done:\n",
    "#             _rew = reward.cpu()\n",
    "#             if not flag_collecting_exp:\n",
    "#                 print(\"Episode %d finish with reward = %.2f\" % (i_episode, _rew.data.numpy().flatten()))\n",
    "#                 print(\"------------------------------------------------\")\n",
    "            break\n",
    "        \n",
    "        # move on\n",
    "        state.data.copy_(next_state.data)\n",
    "    \n",
    "    if i_episode % 50 == 0 and not flag_collecting_exp:\n",
    "        actor_accumulated_reward.append(checkout_actor())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(actor_accumulated_reward)\n",
    "plt.ylabel(\"Accumulated reward\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1000 [ACTOR] Finish after 101 step\tAccumulated reward:2.492\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "checkout_actor(True)\n",
    "\n",
    "time.sleep(1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(agent.actor.state_dict(), 'lunarlander_ddpg_actor.pth')\n",
    "# torch.save(agent.critic.state_dict(), 'lunarlander_ddpg_critic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
